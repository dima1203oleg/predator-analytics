#!/usr/bin/env python3
"""
Standalone Telegram Bot - –ü–æ–≤–Ω—ñ—Å—Ç—é –∞–≤—Ç–æ–Ω–æ–º–Ω–∏–π –±–æ—Ç
–ü—Ä–∞—Ü—é—î –±–µ–∑ FastAPI, —Ç—ñ–ª—å–∫–∏ polling
"""
import asyncio
import logging
import os
import sys
import re
import subprocess
import json
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
import httpx

# Add project to path
sys.path.insert(0, "/Users/dima-mac/Documents/Predator_21/ua-sources")

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('telegram_bot.log')
    ]
)
logger = logging.getLogger(__name__)

# ============================================================
# CONFIGURATION
# ============================================================

BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "7879930188:AAGH8OYUjfun382FCEPowrC0_WKjwVRpcBQ")
API_URL = f"https://api.telegram.org/bot{BOT_TOKEN}"
SSH_CONFIG_PATH = os.path.expanduser("~/.ssh/config")
PROJECT_DIR = "/Users/dima-mac/Documents/Predator_21"

# Authorized users (your Telegram user IDs)
AUTHORIZED_USERS: List[int] = []  # Empty = all users allowed


# ============================================================
# DATA CLASSES
# ============================================================

@dataclass
class NgrokInfo:
    ssh_host: str
    ssh_port: int
    http_url: str
    raw_message: str
    parsed_at: datetime


# Global state
last_ngrok: Optional[NgrokInfo] = None


# ============================================================
# NGROK PARSING
# ============================================================

def parse_ngrok_message(text: str) -> Optional[NgrokInfo]:
    """Parse ngrok URLs from message"""
    ssh_pattern = r'SSH:\s*tcp://([^:]+):(\d+)'
    http_pattern = r'HTTP:\s*(https?://[^\s]+)'
    
    ssh_match = re.search(ssh_pattern, text)
    http_match = re.search(http_pattern, text)
    
    if ssh_match:
        return NgrokInfo(
            ssh_host=ssh_match.group(1),
            ssh_port=int(ssh_match.group(2)),
            http_url=http_match.group(1) if http_match else "",
            raw_message=text,
            parsed_at=datetime.now(timezone.utc)
        )
    return None


def update_ssh_config(ngrok_info: NgrokInfo) -> Tuple[bool, str]:
    """Update SSH config with new ngrok data"""
    global last_ngrok
    
    try:
        if not os.path.exists(SSH_CONFIG_PATH):
            return False, f"‚ùå SSH config –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {SSH_CONFIG_PATH}"
        
        with open(SSH_CONFIG_PATH, 'r') as f:
            content = f.read()
        
        # Find dev-ngrok block
        pattern = r'(Host\s+dev-ngrok\s*\n(?:[^\n]*\n)*?)(?=Host\s|\Z)'
        match = re.search(pattern, content, re.IGNORECASE)
        
        if match:
            old_block = match.group(1)
            new_block = re.sub(r'HostName\s+\S+', f'HostName {ngrok_info.ssh_host}', old_block)
            new_block = re.sub(r'Port\s+\d+', f'Port {ngrok_info.ssh_port}', new_block)
            content = content.replace(old_block, new_block)
        else:
            # Add new block
            new_block = f"""
Host dev-ngrok
    HostName {ngrok_info.ssh_host}
    Port {ngrok_info.ssh_port}
    User root
    IdentityFile ~/.ssh/id_rsa
    StrictHostKeyChecking no
    UserKnownHostsFile /dev/null
"""
            content += new_block
        
        with open(SSH_CONFIG_PATH, 'w') as f:
            f.write(content)
        
        last_ngrok = ngrok_info
        
        return True, f"""‚úÖ *SSH Config –æ–Ω–æ–≤–ª–µ–Ω–æ!*

üîó *–ù–æ–≤—ñ ngrok –¥–∞–Ω—ñ:*
‚Ä¢ Host: `{ngrok_info.ssh_host}`
‚Ä¢ Port: `{ngrok_info.ssh_port}`
‚Ä¢ HTTP: {ngrok_info.http_url}

üì° *–ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è:*
```bash
ssh dev-ngrok
```"""
        
    except Exception as e:
        logger.error(f"Failed to update SSH config: {e}")
        return False, f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}"


# ============================================================
# COMMAND HANDLERS
# ============================================================

async def cmd_start(args: str) -> str:
    return """üöÄ *Predator Analytics Assistant*

–í—ñ—Ç–∞—é! –Ø —Ç–≤—ñ–π AI-–ø–æ–º—ñ—á–Ω–∏–∫ –¥–ª—è —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —Å–µ—Ä–≤–µ—Ä–æ–º.

*–©–æ —è –≤–º—ñ—é:*
‚Ä¢ üìä –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Å–µ—Ä–≤–µ—Ä–∞ (CPU, RAM, Disk)
‚Ä¢ üê≥ Docker/K8s —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è
‚Ä¢ üîó –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è ngrok/SSH
‚Ä¢ üìù –ü–µ—Ä–µ–≥–ª—è–¥ –ª–æ–≥—ñ–≤
‚Ä¢ üí¨ –í—ñ–¥–ø–æ–≤—ñ–¥–∞—é –Ω–∞ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è

*–ù–∞–¥—ñ—à–ª–∏ ngrok –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è* - –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–Ω–æ–≤–ª—é SSH config!

–ö–æ–º–∞–Ω–¥–∏: /help"""


async def cmd_help(args: str) -> str:
    return """üìñ *–ö–æ–º–∞–Ω–¥–∏*

*–°–µ—Ä–≤–µ—Ä:*
‚Ä¢ /status - –ó–∞–≥–∞–ª—å–Ω–∏–π —Å—Ç–∞—Ç—É—Å
‚Ä¢ /disk - –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –¥–∏—Å–∫—É
‚Ä¢ /memory - RAM
‚Ä¢ /cpu - CPU
‚Ä¢ /uptime - –ê–ø—Ç–∞–π–º

*Docker/K8s:*
‚Ä¢ /docker - –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏
‚Ä¢ /pods - K8s –ø–æ–¥–∏
‚Ä¢ /logs [—Å–µ—Ä–≤—ñ—Å] - –õ–æ–≥–∏

*–ú–µ—Ä–µ–∂–∞:*
‚Ä¢ /ngrok - –ü–æ—Ç–æ—á–Ω—ñ ngrok –¥–∞–Ω—ñ
‚Ä¢ /ssh - SSH –∫–æ–Ω—Ñ—ñ–≥
‚Ä¢ /connect - –Ø–∫ –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—å

*Deploy:*
‚Ä¢ /git - Git —Å—Ç–∞—Ç—É—Å
‚Ä¢ /deploy - Deploy —ñ–Ω—Ñ–æ

üí° –ê–±–æ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ!"""


async def cmd_status(args: str) -> str:
    global last_ngrok
    ngrok_status = f"‚úÖ –ê–∫—Ç–∏–≤–Ω–∏–π ({last_ngrok.ssh_host}:{last_ngrok.ssh_port})" if last_ngrok else "‚ö†Ô∏è –û—á—ñ–∫—É—é –¥–∞–Ω—ñ"
    
    return f"""üìä *–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏*

üñ•Ô∏è Local Mac: Online
üîó Ngrok: {ngrok_status}

–î–µ—Ç–∞–ª—ñ: /disk /memory /cpu"""


async def cmd_disk(args: str) -> str:
    try:
        result = subprocess.run(["df", "-h", "/"], capture_output=True, text=True, timeout=5)
        return f"üíæ *Disk Usage*\n```\n{result.stdout}\n```"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}"


async def cmd_memory(args: str) -> str:
    try:
        result = subprocess.run(["vm_stat"], capture_output=True, text=True, timeout=5)
        lines = result.stdout.split('\n')[:10]
        return f"üß† *Memory Stats*\n```\n{''.join(lines)}\n```"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}"


async def cmd_cpu(args: str) -> str:
    try:
        result = subprocess.run(["top", "-l", "1", "-n", "0"], capture_output=True, text=True, timeout=10)
        for line in result.stdout.split('\n'):
            if 'CPU usage' in line:
                return f"‚ö° *CPU*\n{line}"
        return f"‚ö° *CPU Info*\n```\n{result.stdout[:200]}\n```"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}"


async def cmd_uptime(args: str) -> str:
    try:
        result = subprocess.run(["uptime"], capture_output=True, text=True, timeout=5)
        return f"‚è∞ *Uptime*\n{result.stdout}"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}"


async def cmd_docker(args: str) -> str:
    try:
        result = subprocess.run(
            ["docker", "ps", "--format", "table {{.Names}}\t{{.Status}}"],
            capture_output=True, text=True, timeout=10
        )
        if result.returncode == 0:
            return f"üê≥ *Docker Containers*\n```\n{result.stdout[:1000]}\n```"
        return "‚ö†Ô∏è Docker –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ"
    except Exception as e:
        return f"‚ùå Docker –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π: {e}"


async def cmd_pods(args: str) -> str:
    try:
        ns = args.strip() if args else "default"
        result = subprocess.run(
            ["kubectl", "get", "pods", "-n", ns],
            capture_output=True, text=True, timeout=10
        )
        return f"‚ò∏Ô∏è *Pods ({ns})*\n```\n{result.stdout[:1000]}\n```"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}"


async def cmd_logs(args: str) -> str:
    service = args.strip() if args else "backend"
    try:
        result = subprocess.run(
            ["docker", "logs", "--tail", "15", service],
            capture_output=True, text=True, timeout=10
        )
        output = result.stdout or result.stderr
        return f"üìù *Logs ({service})*\n```\n{output[:1200]}\n```"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}"


async def cmd_ngrok(args: str) -> str:
    global last_ngrok
    if last_ngrok:
        return f"""üîó *Ngrok Info*

‚Ä¢ Host: `{last_ngrok.ssh_host}`
‚Ä¢ Port: `{last_ngrok.ssh_port}`
‚Ä¢ HTTP: {last_ngrok.http_url}
‚Ä¢ Updated: {last_ngrok.parsed_at.strftime('%H:%M:%S')} UTC"""
    return "‚ö†Ô∏è Ngrok –¥–∞–Ω—ñ –Ω–µ –æ—Ç—Ä–∏–º–∞–Ω—ñ. –ù–∞–¥—ñ—à–ª–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ ngrok URLs."


async def cmd_ssh(args: str) -> str:
    try:
        with open(SSH_CONFIG_PATH, 'r') as f:
            content = f.read()
        
        pattern = r'(Host\s+dev-ngrok\s*\n(?:[^\n]*\n)*?)(?=Host\s|\Z)'
        match = re.search(pattern, content, re.IGNORECASE)
        
        if match:
            return f"üì° *SSH Config (dev-ngrok)*\n```\n{match.group(1)}\n```"
        return "‚ö†Ô∏è –ë–ª–æ–∫ dev-ngrok –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}"


async def cmd_connect(args: str) -> str:
    global last_ngrok
    if last_ngrok:
        return f"""üì° *–Ø–∫ –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—å*

*SSH:*
```bash
ssh dev-ngrok
```

–ê–±–æ –Ω–∞–ø—Ä—è–º—É:
```bash
ssh -p {last_ngrok.ssh_port} root@{last_ngrok.ssh_host}
```

*HTTP:* {last_ngrok.http_url}"""
    return "‚ö†Ô∏è Ngrok –¥–∞–Ω—ñ –Ω–µ –æ—Ç—Ä–∏–º–∞–Ω—ñ"


async def cmd_git(args: str) -> str:
    try:
        result = subprocess.run(
            ["git", "log", "-1", "--oneline"],
            capture_output=True, text=True, timeout=10,
            cwd=PROJECT_DIR
        )
        result2 = subprocess.run(
            ["git", "status", "-s"],
            capture_output=True, text=True, timeout=10,
            cwd=PROJECT_DIR
        )
        changes = result2.stdout[:300] if result2.stdout else "Clean ‚úÖ"
        return f"""üì¶ *Git Status*

Last commit: `{result.stdout.strip()}`

Changes:
```
{changes}
```"""
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}"


async def cmd_deploy(args: str) -> str:
    return """üì¶ *Deploy Info*

–î–ª—è –¥–µ–ø–ª–æ—é:
1. `git push origin main`
2. GitHub Actions –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è
3. ArgoCD —Å–∏–Ω—Ö—Ä–æ–Ω—ñ–∑—É—î

GitHub: github.com/dima1203oleg/predator-analytics"""


# ============================================================
#  PREDATOR ANALYTICS ADVANCED COMMANDS
# ============================================================

async def cmd_opensearch(args: str) -> str:
    """OpenSearch —Å—Ç–∞—Ç—É—Å"""
    try:
        opensearch_url = os.getenv("OPENSEARCH_URL", "http://localhost:9200")
        async with httpx.AsyncClient(timeout=5) as client:
            health = await client.get(f"{opensearch_url}/_cluster/health")
            health_data = health.json()
            
            indices = await client.get(f"{opensearch_url}/_cat/indices?format=json")
            indices_data = indices.json()
            
            total_docs = sum(int(idx.get("docs.count", 0) or 0) for idx in indices_data)
            
            result = f"""üî∏ *OpenSearch Status*

Cluster: {health_data.get('cluster_name', 'N/A')}
Status: {health_data.get('status', 'unknown')} 
Indices: {health_data.get('number_of_indices', 0)}
Docs: {total_docs:,}
Active Shards: {health_data.get('active_shards', 0)}

Top Indices:"""
            
            for idx in indices_data[:5]:
                result += f"\n  ‚Ä¢ {idx['index']}: {idx.get('docs.count', 0)} docs"
            
            return result
    except Exception as e:
        return f"‚ùå OpenSearch offline: {str(e)}"


async def cmd_qdrant(args: str) -> str:
    """Qdrant —Å—Ç–∞—Ç—É—Å"""
    try:
        qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")
        async with httpx.AsyncClient(timeout=5) as client:
            collections = await client.get(f"{qdrant_url}/collections")
            coll_data = collections.json()
            
            result = "üîπ *Qdrant Vector DB*\n\n"
            
            for coll in coll_data.get("result", {}).get("collections", []):
                coll_name = coll.get("name")
                info = await client.get(f"{qdrant_url}/collections/{coll_name}")
                info_data = info.json().get("result", {})
                
                result += f"üì¶ {coll_name}\n"
                result += f"  Vectors: {info_data.get('points_count', 0):,}\n"
                result += f"  Status: {info_data.get('status', 'unknown')}\n\n"
            
            return result or "‚ö†Ô∏è No collections"
    except Exception as e:
        return f"‚ùå Qdrant offline: {str(e)}"


async def cmd_celery_status(args: str) -> str:
    """Celery workers —Å—Ç–∞—Ç—É—Å"""
    try:
        result = subprocess.run(
            ["celery", "-A", "app.core.celery_app", "inspect", "active"],
            capture_output=True, text=True, timeout=10,
            cwd=f"{PROJECT_DIR}/ua-sources"
        )
        
        if result.returncode == 0:
            return f"üî∏ *Celery Workers*\n```\n{result.stdout[:800]}\n```"
        return "‚ö†Ô∏è Celery offline"
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


async def cmd_etl_jobs(args: str) -> str:
    """ETL jobs —Å—Ç–∞—Ç—É—Å"""
    try:
        backend_url = os.getenv("BACKEND_URL", "http://localhost:8000")
        async with httpx.AsyncClient(timeout=5) as client:
            response = await client.get(f"{backend_url}/api/etl/jobs")
            data = response.json()
            
            result = f"""üîπ *ETL Pipeline*

Total Jobs: {data.get('total', 0)}"""
            
            for job in data.get('jobs', [])[:5]:
                result += f"\n  ‚Ä¢ {job.get('id', 'N/A')}: {job.get('status', 'unknown')}"
            
            return result
    except Exception as e:
        return f"‚ùå ETL service offline: {str(e)}"


async def cmd_k8s_cluster(args: str) -> str:
    """–î–µ—Ç–∞–ª—å–Ω–∏–π —Å—Ç–∞—Ç—É—Å K8s"""
    try:
        # Nodes
        nodes_result = subprocess.run(
            ["kubectl", "get", "nodes", "-o", "json"],
            capture_output=True, text=True, timeout=10
        )
        
        result = "‚ò∏Ô∏è *Kubernetes Cluster*\n\n"
        
        if nodes_result.returncode == 0:
            nodes_json = json.loads(nodes_result.stdout)
            result += f"**Nodes:** {len(nodes_json.get('items', []))}\n"
            for node in nodes_json.get('items', []):
                name = node['metadata']['name']
                ready = node['status']['conditions'][-1]['status'] == "True"
                result += f"  ‚Ä¢ {name}: {'‚úÖ' if ready else '‚ùå'}\n"
        
        # Pods summary
        pods_result = subprocess.run(
            ["kubectl", "get", "pods", "--all-namespaces", "-o", "json"],
            capture_output=True, text=True, timeout=10
        )
        
        if pods_result.returncode == 0:
            pods_json = json.loads(pods_result.stdout)
            running = sum(1 for p in pods_json.get('items', []) if p['status'].get('phase') == 'Running')
            total = len(pods_json.get('items', []))
            result += f"\n**Pods:** {running}/{total} Running\n"
        
        return result
    except Exception as e:
        return f"‚ùå K8s error: {str(e)}"


async def cmd_full_status(args: str) -> str:
    """–ü–æ–≤–Ω–∏–π —Å—Ç–∞—Ç—É—Å Predator Analytics"""
    try:
        # Import advanced monitoring
        from app.services.telegram_advanced import get_full_system_status
        return await get_full_system_status()
    except Exception as e:
        # Fallback to basic status
        tasks = [
            cmd_opensearch(""),
            cmd_qdrant(""),
            cmd_celery_status(""),
            cmd_k8s_cluster("")
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return "\n\n".join(str(r) for r in results if r)


async def cmd_parsing_status(args: str) -> str:
    """–°—Ç–∞—Ç—É—Å –ø–∞—Ä—Å–∏–Ω–≥—É"""
    try:
        backend_url = os.getenv("BACKEND_URL", "http://localhost:8000")
        async with httpx.AsyncClient(timeout=5) as client:
            # ETL jobs
            etl_response = await client.get(f"{backend_url}/api/etl/jobs")
            etl_data = etl_response.json()
            
            result = f"""üì• *–ü–∞—Ä—Å–∏–Ω–≥ / ETL*

Active Jobs: {etl_data.get('total', 0)}

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–π /opensearch –¥–ª—è —ñ–Ω–¥–µ–∫—Å—ñ–≤
–í–∏–∫–æ—Ä–∏—Å—Ç–∞–π /etl –¥–ª—è –¥–µ—Ç–∞–ª–µ–π"""
            
            return result
    except Exception as e:
        return f"‚ö†Ô∏è Backend offline\n\nüí° –ó–∞–ø—É—Å—Ç–∏: `docker compose up -d backend`"


async def cmd_indexing_status(args: str) -> str:
    """–°—Ç–∞—Ç—É—Å —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó"""
    result = "üìä *–Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è*\n\n"
    
    try:
        opensearch_url = os.getenv("OPENSEARCH_URL", "http://localhost:9200")
        async with httpx.AsyncClient(timeout=5) as client:
            indices = await client.get(f"{opensearch_url}/_cat/indices?format=json")
            indices_data = indices.json()
            
            total_docs = sum(int(idx.get("docs.count", 0) or 0) for idx in indices_data)
            
            result += f"**OpenSearch:**\n"
            result += f"  Indices: {len(indices_data)}\n"
            result += f"  Documents: {total_docs:,}\n\n"
    except:
        result += "  ‚ùå OpenSearch offline\n\n"
    
    try:
        qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")
        async with httpx.AsyncClient(timeout=5) as client:
            collections = await client.get(f"{qdrant_url}/collections")
            coll_data = collections.json()
            
            total_vectors = 0
            for coll in coll_data.get("result", {}).get("collections", []):
                coll_name = coll.get("name")
                info = await client.get(f"{qdrant_url}/collections/{coll_name}")
                total_vectors += info.json().get("result", {}).get("points_count", 0)
            
            result += f"**Qdrant:**\n"
            result += f"  Collections: {len(coll_data.get('result', {}).get('collections', []))}\n"
            result += f"  Vectors: {total_vectors:,}\n"
    except:
        result += "  ‚ùå Qdrant offline\n"
    
    return result


# ============================================================
# AI PROGRAMMING AGENT
# ============================================================

async def cmd_code(args: str) -> str:
    """–í–∏–∫–æ–Ω–∞—Ç–∏ Python –∫–æ–¥"""
    if not args:
        return """üíª *AI Code Agent*

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
```
/code print("Hello World")
```

–ê–±–æ –±–∞–≥–∞—Ç–æ—Ä—è–¥–∫–æ–≤–∏–π:
```
/code
import os
print(os.getcwd())
```

‚ö†Ô∏è –ë–µ–∑–ø–µ—á–Ω–æ –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –ø—Ä–æ–µ–∫—Ç—É"""
    
    try:
        # Create temp file
        temp_file = f"/tmp/tg_code_{datetime.now().timestamp()}.py"
        with open(temp_file, 'w') as f:
            f.write(args)
        
        # Execute
        result = subprocess.run(
            ["python3", temp_file],
            capture_output=True, text=True, timeout=30,
            cwd=PROJECT_DIR
        )
        
        os.remove(temp_file)
        
        output = result.stdout or result.stderr
        status = "‚úÖ" if result.returncode == 0 else "‚ùå"
        
        return f"""{status} *Code Execution*

```python
{args[:200]}
```

**Output:**
```
{output[:1000]}
```"""
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


async def cmd_bash(args: str) -> str:
    """–í–∏–∫–æ–Ω–∞—Ç–∏ bash –∫–æ–º–∞–Ω–¥—É"""
    if not args:
        return """üíª *Bash Executor*

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
```
/bash ls -la
```

‚ö†Ô∏è –ü—Ä–∞—Ü—é—î –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –ø—Ä–æ–µ–∫—Ç—É"""
    
    try:
        result = subprocess.run(
            args, shell=True,
            capture_output=True, text=True, timeout=30,
            cwd=PROJECT_DIR
        )
        
        output = result.stdout or result.stderr
        status = "‚úÖ" if result.returncode == 0 else "‚ùå"
        
        return f"""{status} *Bash*

```bash
{args}
```

**Output:**
```
{output[:1200]}
```"""
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


async def cmd_test(args: str) -> str:
    """–ó–∞–ø—É—Å—Ç–∏—Ç–∏ —Ç–µ—Å—Ç–∏"""
    try:
        cmd = ["pytest", "-v"]
        if args:
            cmd.append(args)
        
        result = subprocess.run(
            cmd,
            capture_output=True, text=True, timeout=60,
            cwd=f"{PROJECT_DIR}/ua-sources"
        )
        
        output = result.stdout or result.stderr
        status = "‚úÖ PASSED" if result.returncode == 0 else "‚ùå FAILED"
        
        return f"""üß™ *Tests {status}*

```
{output[-1200:]}
```"""
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


async def cmd_create_file(args: str) -> str:
    """–°—Ç–≤–æ—Ä–∏—Ç–∏ —Ñ–∞–π–ª —á–µ—Ä–µ–∑ –±–æ—Ç"""
    if not args or "\n" not in args:
        return """üìù *Create File*

–§–æ—Ä–º–∞—Ç:
```
/create path/to/file.py
def hello():
    print("Hello")
```"""
    
    parts = args.split("\n", 1)
    path = parts[0].strip()
    content = parts[1] if len(parts) > 1 else ""
    
    try:
        full_path = os.path.join(PROJECT_DIR, path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        
        with open(full_path, 'w') as f:
            f.write(content)
        
        return f"""‚úÖ *File Created*

Path: `{path}`
Size: {len(content)} bytes"""
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


# ============================================================
# LLM MANAGEMENT COMMANDS
# ============================================================

async def cmd_llm_providers(args: str) -> str:
    """–°–ø–∏—Å–æ–∫ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ñ–≤"""
    try:
        async with httpx.AsyncClient(timeout=5) as client:
            response = await client.get(f"{os.getenv('BACKEND_URL', 'http://localhost:8000')}/api/llm/providers")
            providers = response.json()
        
        result = "üß† **LLM –ü—Ä–æ–≤–∞–π–¥–µ—Ä–∏**\n\n"
        
        active = [p for p in providers if p['api_keys']]
        inactive = [p for p in providers if not p['api_keys']]
        
        if active:
            result += "**‚úÖ –ê–∫—Ç–∏–≤–Ω—ñ:**\n"
            for p in active:
                emoji = get_provider_emoji_local(p['id'])
                status = "‚úÖ" if p['enabled'] else "‚ùå"
                free_tag = "üÜì" if p['free'] else "üí∞"
                result += f"{emoji} {p['name']} {status} {free_tag}\n"
                result += f"  üîë {len(p['api_keys'])} –∫–ª—é—á—ñ–≤\n"
                result += f"  üì¶ {p['model']}\n\n"
        
        if inactive[:5]:  # Show only first 5
            result += "**‚ûï –î–æ—Å—Ç—É–ø–Ω—ñ –¥–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è:**\n"
            for p in inactive[:5]:
                emoji = get_provider_emoji_local(p['id'])
                free_tag = "üÜì" if p['free'] else "üí∞"
                result += f"{emoji} {p['name']} {free_tag}\n"
        
        result += f"\n–í—Å—å–æ–≥–æ: {len(active)} –∞–∫—Ç–∏–≤–Ω–∏—Ö / {len(providers)} –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ñ–≤"
        return result
        
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


async def cmd_llm_add(args: str) -> str:
    """–î–æ–¥–∞—Ç–∏ API –∫–ª—é—á"""
    if not args or ' ' not in args:
        return """üîë **–î–æ–¥–∞—Ç–∏ API –∫–ª—é—á**

–§–æ—Ä–º–∞—Ç:
```
/llm_add groq gsk_xxxxx
/llm_add gemini AIzaxxx
```

–ü—Ä–æ–≤–∞–π–¥–µ—Ä–∏:
‚Ä¢ groq, gemini, openai
‚Ä¢ mistral, cohere, together
‚Ä¢ xai, deepseek, huggingface

–ê–±–æ –ø—Ä–∏—Ä–æ–¥–Ω–æ:
"–î–æ–¥–∞–π –∫–ª—é—á Groq: gsk_xxx"
"""
    
    parts = args.strip().split(maxsplit=1)
    if len(parts) != 2:
        return "‚ùå –§–æ—Ä–º–∞—Ç: `/llm_add <provider> <key>`"
    
    provider_id, api_key = parts
    
    try:
        logger.info(f"Adding LLM key for {provider_id}...")
        
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(
                f"{os.getenv('BACKEND_URL', 'http://localhost:8000')}/api/llm/providers/{provider_id}/keys",
                json={
                    "provider_id": provider_id,
                    "api_key": api_key,
                    "test": True
                }
            )
            data = response.json()
        
        emoji = get_provider_emoji_local(provider_id)
        return f"""‚úÖ **–ö–ª—é—á –¥–æ–¥–∞–Ω–æ!**

{emoji} –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {provider_id.title()}
üîë –í—Å—å–æ–≥–æ –∫–ª—é—á—ñ–≤: {data.get('total_keys', 1)}

{data.get('message', 'Success')}"""
        
    except httpx.HTTPStatusError as e:
        if e.response.status_code == 400:
            return f"‚ùå **–¢–µ—Å—Ç –∫–ª—é—á–∞ –ø—Ä–æ–≤–∞–ª–∏–≤—Å—è**\n\n{e.response.json().get('detail', 'Invalid key')}"
        return f"‚ùå Error: {e.response.json().get('detail', str(e))}"
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


async def cmd_llm_test(args: str) -> str:
    """–¢–µ—Å—Ç—É–≤–∞—Ç–∏ API –∫–ª—é—á"""
    if not args or ' ' not in args:
        return """üß™ **–¢–µ—Å—Ç—É–≤–∞—Ç–∏ –∫–ª—é—á**

–§–æ—Ä–º–∞—Ç:
```
/llm_test groq gsk_xxxxx
```"""
    
    parts = args.strip().split(maxsplit=1)
    if len(parts) != 2:
        return "‚ùå –§–æ—Ä–º–∞—Ç: `/llm_test <provider> <key>`"
    
    provider_id, api_key = parts
    
    try:
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(
                f"{os.getenv('BACKEND_URL', 'http://localhost:8000')}/api/llm/providers/{provider_id}/test",
                json={
                    "provider_id": provider_id,
                    "api_key": api_key
                }
            )
            result = response.json()
        
        if result['success']:
            return f"""‚úÖ **–ö–ª—é—á –≤–∞–ª—ñ–¥–Ω–∏–π!**

‚è±Ô∏è Latency: {result.get('latency_ms', 0):.0f}ms
üì¶ Model: {result.get('model', 'N/A')}
üí¨ {result.get('message', 'Test passed')}"""
        else:
            return f"‚ùå **–ö–ª—é—á –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π**\n\n{result.get('error', 'Unknown error')}"
            
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


async def cmd_llm_stats(args: str) -> str:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ LLM"""
    try:
        async with httpx.AsyncClient(timeout=5) as client:
            response = await client.get(f"{os.getenv('BACKEND_URL', 'http://localhost:8000')}/api/llm/stats")
            stats = response.json()
        
        return f"""üìä **LLM Statistics**

üî¢ –í—Å—å–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ñ–≤: {stats['total_providers']}
‚úÖ –ê–∫—Ç–∏–≤–Ω–∏—Ö: {stats['active_providers']}
üîë –í—Å—å–æ–≥–æ –∫–ª—é—á—ñ–≤: {stats['total_keys']}

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–π /llm_providers –¥–ª—è –¥–µ—Ç–∞–ª–µ–π"""
        
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


def get_provider_emoji_local(provider_id: str) -> str:
    """Emoji –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
    emojis = {
        "groq": "‚ö°",
        "gemini": "üß†",
        "openai": "üí∞",
        "anthropic": "üé®",
        "mistral": "‚öñÔ∏è",
        "cohere": "üí°",
        "together": "ü§ù",
        "xai": "üéØ",
        "deepseek": "üöÄ",
        "huggingface": "ü§ó",
        "openrouter": "üîÄ",
        "ollama": "üè†"
    }
    return emojis.get(provider_id, "ü§ñ")



# Command mapping
COMMANDS = {
    # Basic
    "start": cmd_start,
    "help": cmd_help,
    "menu": cmd_start,
    
    # Server
    "status": cmd_status,
    "disk": cmd_disk,
    "memory": cmd_memory,
    "cpu": cmd_cpu,
    "uptime": cmd_uptime,
    
    # Docker/K8s
    "docker": cmd_docker,
    "pods": cmd_pods,
    "logs": cmd_logs,
    "cluster": cmd_k8s_cluster,
    
    # Network
    "ngrok": cmd_ngrok,
    "ssh": cmd_ssh,
    "connect": cmd_connect,
    
    # Deploy
    "git": cmd_git,
    "deploy": cmd_deploy,
    
    # Predator Analytics
    "opensearch": cmd_opensearch,
    "qdrant": cmd_qdrant,
    "celery": cmd_celery_status,
    "etl": cmd_etl_jobs,
    "parsing": cmd_parsing_status,
    "indexing": cmd_indexing_status,
    "fullstatus": cmd_full_status,
    "predator": cmd_full_status,
    
    # AI Programming
    "code": cmd_code,
    "bash": cmd_bash,
    "test": cmd_test,
    "create": cmd_create_file,
    
    # LLM Management
    "llm_providers": cmd_llm_providers,
    "llm_add": cmd_llm_add,
    "llm_test": cmd_llm_test,
    "llm_stats": cmd_llm_stats,
}

# Emoji to command mapping
EMOJI_MAP = {
    # Basic
    "üìä": "status", "—Å—Ç–∞—Ç—É—Å": "status",
    "üñ•Ô∏è": "status", "—Å–µ—Ä–≤–µ—Ä": "status",
    
    # Docker/K8s
    "üê≥": "docker", "docker": "docker",
    "‚ò∏Ô∏è": "cluster", "k8s": "cluster", "–∫–ª–∞—Å—Ç–µ—Ä": "cluster",
    
    # Network
    "üîó": "ngrok", "ngrok": "ngrok",
    "üì°": "ssh", "ssh": "ssh", "ssh config": "ssh",
    
    # Deploy
    "üì¶": "deploy", "deploy": "deploy", "–¥–µ–ø–ª–æ–π": "deploy",
    
   # Predator Analytics
    "üóÑÔ∏è": "opensearch", "opensearch": "opensearch",
    "üß†": "qdrant", "qdrant": "qdrant",
    "‚öôÔ∏è": "celery", "celery": "celery",
    "üì•": "parsing", "–ø–∞—Ä—Å–∏–Ω–≥": "parsing",
    "üìä": "indexing", "—ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—è": "indexing",
    "üéØ": "predator", "–ø—Ä–µ–¥–∞—Ç–æ—Ä": "predator",
    
    # Programming
    "üíª": "code", "–∫–æ–¥": "code",
    "üî®": "bash",
    "üß™": "test", "—Ç–µ—Å—Ç–∏": "test",
    
    # Help  
    "‚ùì": "help", "–¥–æ–ø–æ–º–æ–≥–∞": "help",
}


# Main menu keyboard - –†–û–ó–®–ò–†–ï–ù–ï –ú–ï–ù–Æ
MAIN_MENU = {
    "keyboard": [
        [{"text": "üìä –°—Ç–∞—Ç—É—Å"}, {"text": "üéØ Predator"}],
        [{"text": "üóÑÔ∏è OpenSearch"}, {"text": "üß† Qdrant"}],
        [{"text": "üì• –ü–∞—Ä—Å–∏–Ω–≥"}, {"text": "‚öôÔ∏è Celery"}],
        [{"text": "üê≥ Docker"}, {"text": "‚ò∏Ô∏è –ö–ª–∞—Å—Ç–µ—Ä"}],
        [{"text": "üîó Ngrok"}, {"text": "üì° SSH"}],
        [{"text": "üíª –ü—Ä–æ–≥—Ä–∞–º—É–≤–∞—Ç–∏"}, {"text": "üß™ –¢–µ—Å—Ç–∏"}],
        [{"text": "üì¶ Deploy"}, {"text": "‚ùì –î–æ–ø–æ–º–æ–≥–∞"}]
    ],
    "resize_keyboard": True
}


# Updated help command with new features
async def cmd_help_updated(args: str) -> str:
    return """üìñ *–ö–æ–º–∞–Ω–¥–∏ Telegram –ë–æ—Ç–∞*

**üñ•Ô∏è –°–µ—Ä–≤–µ—Ä:**
‚Ä¢ /status - –ó–∞–≥–∞–ª—å–Ω–∏–π —Å—Ç–∞—Ç—É—Å
‚Ä¢ /disk /memory /cpu - –†–µ—Å—É—Ä—Å–∏
‚Ä¢ /uptime - –ê–ø—Ç–∞–π–º

**üê≥ Docker/K8s:**
‚Ä¢ /docker - –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏
‚Ä¢ /pods [namespace] - K8s –ø–æ–¥–∏
‚Ä¢ /cluster - –î–µ—Ç–∞–ª—å–Ω–∏–π —Å—Ç–∞—Ç—É—Å –∫–ª–∞—Å—Ç–µ—Ä—É
‚Ä¢ /logs [—Å–µ—Ä–≤—ñ—Å] - –õ–æ–≥–∏

**üîó –ú–µ—Ä–µ–∂–∞:**
‚Ä¢ /ngrok - –ü–æ—Ç–æ—á–Ω—ñ ngrok –¥–∞–Ω—ñ
‚Ä¢ /ssh - SSH –∫–æ–Ω—Ñ—ñ–≥
‚Ä¢ /connect - –Ø–∫ –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—å

**üìä Predator Analytics:**
‚Ä¢ /predator - –ü–æ–≤–Ω–∏–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏
‚Ä¢ /opensearch - OpenSearch —ñ–Ω–¥–µ–∫—Å–∏
‚Ä¢ /qdrant - Vector DB —Å—Ç–∞—Ç—É—Å
‚Ä¢ /celery - Workers —Ç–∞ tasks
‚Ä¢ /etl - ETL jobs
‚Ä¢ /parsing - –ß–∏ –ø–∞—Ä—Å–∏—Ç—å—Å—è
‚Ä¢ /indexing - –ß–∏ —ñ–Ω–¥–µ–∫—Å—É—î—Ç—å—Å—è

**üíª AI –ü—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è:**
‚Ä¢ /code [python] - –í–∏–∫–æ–Ω–∞—Ç–∏ Python
‚Ä¢ /bash [cmd] - –í–∏–∫–æ–Ω–∞—Ç–∏ bash
‚Ä¢ /test [path] - –ó–∞–ø—É—Å—Ç–∏—Ç–∏ —Ç–µ—Å—Ç–∏
‚Ä¢ /create [path] - –°—Ç–≤–æ—Ä–∏—Ç–∏ —Ñ–∞–π–ª

**üì¶ Deploy:**
‚Ä¢ /git - Git —Å—Ç–∞—Ç—É—Å
‚Ä¢ /deploy - Deploy —ñ–Ω—Ñ–æ

**üí° –ü—Ä–∏–∫–ª–∞–¥–∏:**
```
/code print("Hello!")
/bash ls -la
/opensearch
/predator
```

–ù–∞–¥—ñ—à–ª–∏ **ngrok** –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è - –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–Ω–æ–≤–ª—é SSH!"""

# Update the help command
COMMANDS["help"] = cmd_help_updated


# ============================================================
# AI NATURAL LANGUAGE PROCESSING
# ============================================================

async def understand_intent(text: str) -> Dict[str, Any]:
    """–†–æ–∑—É–º—ñ—î –Ω–∞–º—ñ—Ä –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —á–µ—Ä–µ–∑ AI"""
    text_lower = text.lower()
    
    # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
    intents = {
        "system_status": ["—Å—Ç–∞—Ç—É—Å", "—Å—Ç–∞–Ω", "—è–∫", "–ø—Ä–∞—Ü—é—î", "—Å–∏—Å—Ç–µ–º–∞", "–≤—Å–µ", "–ø—Ä–∞—Ü—é—é—Ç—å", "—Å–µ—Ä–≤—ñ—Å–∏"],
        "opensearch": ["—ñ–Ω–¥–µ–∫—Å", "opensearch", "–¥–æ–∫—É–º–µ–Ω—Ç", "–ø–æ—à—É–∫", "—ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—è", "—ñ–Ω–¥–µ–∫—Å—É—î—Ç—å—Å—è"],
        "qdrant": ["qdrant", "–≤–µ–∫—Ç–æ—Ä", "vector", "embedding", "—Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π"],
        "parsing": ["–ø–∞—Ä—Å", "–µ—Ç–ª", "etl", "–¥–∞–Ω—ñ", "–∑–±—ñ—Ä", "–ø–∞—Ä—Å–∏—Ç—å—Å—è"],
        "celery": ["celery", "worker", "task", "—á–µ—Ä–≥–∞", "–∑–∞–≤–¥–∞–Ω–Ω—è"],
        "k8s": ["kubernetes", "k8s", "–∫–ª–∞—Å—Ç–µ—Ä", "pod", "–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä", "deploy"],
        "docker": ["docker", "–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä"],
        "ngrok": ["ngrok", "—Ç—É–Ω–µ–ª—å", "–ø—ñ–¥–∫–ª—é—á", "ssh", "–¥–æ—Å—Ç—É–ø"],
        "programming": ["–∫–æ–¥", "–ø—Ä–æ–≥—Ä–∞–º", "—Å–∫—Ä–∏–ø—Ç", "–≤–∏–∫–æ–Ω–∞–π", "–∑–∞–ø—É—Å—Ç–∏", "python", "bash"],
        "help": ["–¥–æ–ø–æ–º–æ–≥–∞", "–∫–æ–º–∞–Ω–¥", "—â–æ –≤–º—ñ—î", "–º–æ–∂–µ—à"],
        "greeting": ["–ø—Ä–∏–≤—ñ—Ç", "–≤—ñ—Ç–∞—é", "–∑–¥–æ—Ä–æ–≤", "–¥–æ–±—Ä–∏"],
    }
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–∞–π–∫—Ä–∞—â–∏–π –∑–±—ñ–≥
    best_match = None
    best_score = 0
    
    for intent_name, keywords in intents.items():
        score = sum(1 for kw in keywords if kw in text_lower)
        if score > best_score:
            best_score = score
            best_match = intent_name
    
    if best_match and best_score > 0:
        return {"intent": best_match, "confidence": best_score, "text": text}
    
    # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ - –∑–∞–≥–∞–ª—å–Ω–∏–π –∑–∞–ø–∏—Ç
    return {"intent": "general", "confidence": 0, "text": text}


async def process_natural_language(text: str, chat_id: int) -> str:
    """–û–±—Ä–æ–±–ª—è—î –ø—Ä–∏—Ä–æ–¥–Ω—É –º–æ–≤—É —á–µ—Ä–µ–∑ AI"""
    
    text_lower = text.lower()
    
    # Special: LLM key adding - –ø—Ä–∏—Ä–æ–¥–Ω–∞ –º–æ–≤–∞
    if "–¥–æ–¥–∞–π –∫–ª—é—á" in text_lower or "add key" in text_lower:
        # Parse: "–î–æ–¥–∞–π –∫–ª—é—á Groq: gsk_xxx" or "–î–æ–¥–∞–π –∫–ª—é—á groq gsk_xxx"
        import re
        
        # Try format: "–¥–æ–¥–∞–π –∫–ª—é—á <provider>: <key>"
        match = re.search(r'–¥–æ–¥–∞–π –∫–ª—é—á\s+(\w+)[:\s]+([a-zA-Z0-9_\-]+)', text_lower)
        if not match:
            # Try English
            match = re.search(r'add key\s+(\w+)[:\s]+([a-zA-Z0-9_\-]+)', text_lower)
        
        if match:
            provider = match.group(1).lower()
            # Get actuall key from original text (preserve case)
            key_start = text.find(match.group(2))
            key = text[key_start:key_start+100].split()[0]  # Get first token
            
            return await cmd_llm_add(f"{provider} {key}")
        else:
            return """üîë –î–æ–¥–∞—Ç–∏ –∫–ª—é—á

–§–æ—Ä–º–∞—Ç:
"–î–æ–¥–∞–π –∫–ª—é—á groq: gsk_xxxxx"
–∞–±–æ
"–î–æ–¥–∞–π –∫–ª—é—á gemini AIzaxxxxx"

–ü—Ä–æ–≤–∞–π–¥–µ—Ä–∏: groq, gemini, xai, deepseek, mistral, cohere"""
    
    # –†–æ–∑—É–º—ñ—î–º–æ –Ω–∞–º—ñ—Ä
    intent_data = await understand_intent(text)
    intent = intent_data["intent"]
    
    # –û–±—Ä–æ–±–ª—è—î–º–æ –∑–≥—ñ–¥–Ω–æ –Ω–∞–º—ñ—Ä—É
    if intent == "greeting":
        return """üëã –ü—Ä–∏–≤—ñ—Ç! –Ø Predator Analytics Bot.

üéØ –ú–æ–∂—É –¥–æ–ø–æ–º–æ–≥—Ç–∏ –∑:
‚Ä¢ –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥–æ–º —Å–∏—Å—Ç–µ–º–∏
‚Ä¢ –ü–µ—Ä–µ–≤—ñ—Ä–∫–æ—é —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó
‚Ä¢ –ü—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è–º
‚Ä¢ SSH/ngrok –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è–º–∏

–ü–∏—Ç–∞–π —â–æ –∑–∞–≤–≥–æ–¥–Ω–æ –∞–±–æ /help –¥–ª—è –∫–æ–º–∞–Ω–¥!"""
    
    elif intent == "system_status":
        return await cmd_full_status("")
    
    elif intent == "opensearch":
        return await cmd_opensearch("")
    
    elif intent == "qdrant":
        return await cmd_qdrant("")
    
    elif intent == "parsing":
        return await cmd_parsing_status("")
    
    elif intent == "celery":
        return await cmd_celery_status("")
    
    elif intent == "k8s":
        return await cmd_k8s_cluster("")
    
    elif intent == "docker":
        return await cmd_docker("")
    
    elif intent == "ngrok":
        return await cmd_ngrok("")
    
    elif intent == "programming":
        return """üíª **AI Code Agent**

–Ø –º–æ–∂—É:
‚Ä¢ `/code [python]` - –≤–∏–∫–æ–Ω–∞—Ç–∏ Python
‚Ä¢ `/bash [cmd]` - –∑–∞–ø—É—Å—Ç–∏—Ç–∏ bash
‚Ä¢ `/test` - –∑–∞–ø—É—Å—Ç–∏—Ç–∏ —Ç–µ—Å—Ç–∏

–ü—Ä–∏–∫–ª–∞–¥:
```
/code print("Hello!")
```

–©–æ —Ö–æ—á–µ—à –≤–∏–∫–æ–Ω–∞—Ç–∏?"""
    
    elif intent == "help":
        return await cmd_help_updated("")
    
    # –ó–∞–≥–∞–ª—å–Ω–∏–π AI –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    else:
        # –°–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ–±—É—î–º–æ –∑ –Ω–∞—à–æ—é knowledge base (—Ä–∞–±–æ—Ç–∞—î –±–µ–∑ API!)
        knowledge_response = get_knowledge_based_response(text)
        if knowledge_response:
            return knowledge_response
        
        # –ü–æ—Ç—ñ–º –ø—Ä–æ–±—É—î–º–æ LLM —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π
        try:
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –∑–∞–ø–∏—Ç—É –¥–ª—è –≤–∏–±–æ—Ä—É –º—ñ–∂ council —Ç–∞ –∑–≤–∏—á–∞–π–Ω–∏–º LLM
            from app.services.llm import llm_service
            
            # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ —â–æ –≤–∫–∞–∑—É—é—Ç—å –Ω–∞ —Å–∫–ª–∞–¥–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è
            complex_indicators = [
                "–ø–æ—Ä—ñ–≤–Ω—è–π", "–ø—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π", "–ø–æ—è—Å–Ω–∏ –¥–µ—Ç–∞–ª—å–Ω–æ", "—Ä–æ–∑–∫–∞–∂–∏ –ø—Ä–æ",
                "—è–∫ –ø—Ä–∞—Ü—é—î", "–∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞", "—Å–∏—Å—Ç–µ–º–∞", "plan", "strategy",
                "–ø–æ—Ä–∞–¥–∞", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è", "—â–æ –∫—Ä–∞—â–µ", "–æ–ø–∏—à–∏", "—Ä–æ–∑–∫–∞–∂–∏"
            ]
            
            is_complex = any(indicator in text.lower() for indicator in complex_indicators)
            is_complex = is_complex or len(text.split()) > 15  # –î–æ–≤–≥–µ –ø–∏—Ç–∞–Ω–Ω—è = —Å–∫–ª–∞–¥–Ω–µ
            
            system_prompt = """–¢–∏ - AI –∞—Å–∏—Å—Ç–µ–Ω—Ç Predator Analytics Bot.
–î–æ–ø–æ–º–∞–≥–∞–π –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É –∑ –ø–∏—Ç–∞–Ω–Ω—è–º–∏ –ø—Ä–æ:
- –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º–∏ (OpenSearch, Qdrant, Celery, K8s)
- –ü—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ Telegram
- –£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —Å–µ—Ä–≤–µ—Ä–æ–º
- SSH/ngrok –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
- –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É Predator Analytics

–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –∫–æ—Ä–æ—Ç–∫–æ —Ç–∞ –ø–æ —Å—É—Ç—ñ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é.
–Ø–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ - –≤–∫–∞–∂–∏ —è–∫—É."""
            
            if is_complex:
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ LLM Council –¥–ª—è –≥–ª–∏–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
                logger.info(f"Using LLM Council for complex query: {text[:50]}...")
                
                response = await llm_service.generate_with_routing(
                    prompt=text,
                    system=system_prompt,
                    mode="council",  # üî• Council mode!
                    max_tokens=1500
                )
                
                if response.success:
                    # –î–æ–¥–∞—î–º–æ –º—ñ—Ç–∫—É —â–æ —Ü–µ council –≤—ñ–¥–ø–æ–≤—ñ–¥—å
                    prefix = "üß† **Council AI** (5 –º–æ–¥–µ–ª–µ–π)\n\n"
                    return f"{prefix}{response.content[:1500]}\n\n_‚è±Ô∏è {response.latency_ms:.0f}ms | {response.model}_"
            else:
                # –ó–≤–∏—á–∞–π–Ω–∏–π fast —Ä–µ–∂–∏–º –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö –ø–∏—Ç–∞–Ω—å
                response = await llm_service.generate_with_routing(
                    prompt=text,
                    system=system_prompt,
                    mode="fast"
                )
                
                if response.success:
                    return f"ü§ñ {response.content[:1000]}"
            
        except Exception as e:
            logger.error(f"AI processing error: {e}")
        
        # Final fallback - –ø–æ–∫–∞–∑—É—î–º–æ –¥–æ–ø–æ–º–æ–≥—É
        return """üí° –ú–æ–∂—É –¥–æ–ø–æ–º–æ–≥—Ç–∏!

–î–ª—è –∫—Ä–∞—â–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π –Ω–∞–ª–∞—à—Ç—É–π LLM API –∫–ª—é—á—ñ.

–ê–±–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–π –∫–æ–º–∞–Ω–¥–∏:
‚Ä¢ `/predator` - –ü–æ–≤–Ω–∏–π —Å—Ç–∞—Ç—É—Å
‚Ä¢ `/opensearch` - OpenSearch
‚Ä¢ `/qdrant` - Qdrant
‚Ä¢ `/parsing` - –ü–∞—Ä—Å–∏–Ω–≥
‚Ä¢ `/code` - –í–∏–∫–æ–Ω–∞—Ç–∏ –∫–æ–¥

–ê–±–æ —É—Ç–æ—á–Ω–∏: "—Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏", "–ø–æ–∫–∞–∂–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏" —Ç–æ—â–æ."""


def get_knowledge_based_response(text: str) -> Optional[str]:
    """
    Knowledge base - –≤–±—É–¥–æ–≤–∞–Ω—ñ –∑–Ω–∞–Ω–Ω—è –ø—Ä–æ —Å–∏—Å—Ç–µ–º—É
    –ü—Ä–∞—Ü—é—î –ë–ï–ó LLM API!
    """
    text_lower = text.lower()
    
    # –ü–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ –≤–µ–± —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å / frontend
    if any(kw in text_lower for kw in ["–≤–µ–±", "—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å", "frontend", "—Ñ—Ä–æ–Ω—Ç–µ–Ω–¥", "ui", "–¥–∏–∑–∞–π–Ω"]):
        return """üé® **–í–µ–± —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å Predator Analytics**

**–¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó:**
‚Ä¢ React 18 + TypeScript
‚Ä¢ Vite (build tool)
‚Ä¢ TailwindCSS (styling)
‚Ä¢ Recharts (–≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó)

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏:**
‚Ä¢ Dashboard - –≥–æ–ª–æ–≤–Ω–∞ –ø–∞–Ω–µ–ª—å
‚Ä¢ Search Console - –ø–æ—à—É–∫
‚Ä¢ Analytics View - –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞
‚Ä¢ Settings - –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è

**–§—ñ—á—ñ:**
‚Ä¢ –†–µ–∞–ª-—Ç–∞–π–º –æ–Ω–æ–≤–ª–µ–Ω–Ω—è
‚Ä¢ Dark mode
‚Ä¢ Responsive design
‚Ä¢ AI-assisted search

**–§–∞–π–ª–∏:**
`/frontend/src/`
  - components/ - React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
  - views/ - —Å—Ç–æ—Ä—ñ–Ω–∫–∏
  - context/ - state management
  - index.css - —Å—Ç–∏–ª—ñ

–ü–æ—Ç—Ä—ñ–±–Ω–æ –±—ñ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π? –ü–∏—Ç–∞–π –ø—Ä–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç!"""
    
    # –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º–∏
    if any(kw in text_lower for kw in ["–∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä", "–∫–æ–º–ø–æ–Ω–µ–Ω—Ç", "—Å—Ç—Ä—É–∫—Ç—É—Ä", "—Å–∏—Å—Ç–µ–º–∞"]):
        return """üèóÔ∏è **–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ Predator Analytics**

**–®–∞—Ä–∏:**

1Ô∏è‚É£ **Frontend**
   - React/TypeScript + Vite
   - TailwindCSS
   - Real-time dashboard

2Ô∏è‚É£ **Backend API**
   - FastAPI (Python)
   - Async/await
   - Multi-provider LLM

3Ô∏è‚É£ **Databases**
   - PostgreSQL - –æ—Å–Ω–æ–≤–Ω–∞ –ë–î
   - OpenSearch - full-text –ø–æ—à—É–∫
   - Qdrant - vector DB
   - Redis - –∫–µ—à

4Ô∏è‚É£ **ETL Pipeline**
   - Celery workers
   - Scheduled crawlers
   - Data normalization

5Ô∏è‚É£ **ML/AI**
   - LLM Council (5 –º–æ–¥–µ–ª–µ–π)
   - Embeddings service
   - Semantic search

6Ô∏è‚É£ **Infrastructure**
   - Docker Compose (local)
   - K8s/K3s (prod)
   - ArgoCD (GitOps)
   - Grafana (monitoring)

–î–µ—Ç–∞–ª—å–Ω–æ: `/predator` –∞–±–æ –ø–∏—Ç–∞–π –ø—Ä–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π —à–∞—Ä!"""
    
    # Backend
    if any(kw in text_lower for kw in ["backend", "api", "fastapi", "–±–µ–∫–µ–Ω–¥"]):
        return """‚öôÔ∏è **Backend API**

**Stack:**
‚Ä¢ FastAPI (Python 3.11+)
‚Ä¢ Async/await –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞
‚Ä¢ Pydantic –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
‚Ä¢ SQLAlchemy ORM

**Endpoints:**
‚Ä¢ `/api/search` - –ø–æ—à—É–∫
‚Ä¢ `/api/analytics` - –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞
‚Ä¢ `/api/etl` - ETL jobs
‚Ä¢ `/api/telegram` - –±–æ—Ç webhook

**Services:**
‚Ä¢ LLM Service - multi-provider
‚Ä¢ AI Engine - —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫
‚Ä¢ Crawler Service - –ø–∞—Ä—Å–∏–Ω–≥
‚Ä¢ Embedding Service - –≤–µ–∫—Ç–æ—Ä–∏

**–§–∞–π–ª–∏:** `/ua-sources/app/`

–©–æ —Å–∞–º–µ —Ü—ñ–∫–∞–≤–∏—Ç—å?"""
    
    # Databases
    if any(kw in text_lower for kw in ["–±–∞–∑–∞", "database", "opensearch", "qdrant", "postgres"]):
        return """üóÑÔ∏è **Databases**

**PostgreSQL**
‚Ä¢ –û—Å–Ω–æ–≤–Ω–∞ –ë–î
‚Ä¢ Companies, tenders, analytics
‚Ä¢ SQLAlchemy ORM

**OpenSearch**
‚Ä¢ Full-text search
‚Ä¢ ~15,000+ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
‚Ä¢ Hybrid search (BM25 + vectors)

**Qdrant**
‚Ä¢ Vector database
‚Ä¢ Semantic embeddings
‚Ä¢ 384-dim vectors

**Redis**
‚Ä¢ –ö–µ—à—É–≤–∞–Ω–Ω—è
‚Ä¢ Session storage
‚Ä¢ Celery broker

–ö–æ–º–∞–Ω–¥–∏:
‚Ä¢ `/opensearch` - —Å—Ç–∞—Ç—É—Å —ñ–Ω–¥–µ–∫—Å—ñ–≤
‚Ä¢ `/qdrant` - vector –∫–æ–ª–µ–∫—Ü—ñ—ó"""
    
    # ETL / Parsing
    if any(kw in text_lower for kw in ["etl", "–ø–∞—Ä—Å–∏–Ω–≥", "crawler", "–∑–±—ñ—Ä –¥–∞–Ω–∏—Ö"]):
        return """üì• **ETL Pipeline**

**–î–∂–µ—Ä–µ–ª–∞ –¥–∞–Ω–∏—Ö:**
‚Ä¢ EDR (–Ñ–î–†) - —Ä–µ—î—Å—Ç—Ä –∫–æ–º–ø–∞–Ω—ñ–π
‚Ä¢ Prozorro - —Ç–µ–Ω–¥–µ—Ä–∏
‚Ä¢ NBU - –∫—É—Ä—Å–∏ –≤–∞–ª—é—Ç
‚Ä¢ YouControl - –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞

**–ü—Ä–æ—Ü–µ—Å:**
1. Crawlers –∑–±–∏—Ä–∞—é—Ç—å –¥–∞–Ω—ñ
2. Normalization + cleaning
3. OpenSearch indexing
4. Qdrant embeddings
5. PostgreSQL storage

**Celery Workers:**
‚Ä¢ ETL tasks
‚Ä¢ Scheduled crawling
‚Ä¢ Monitoring

**–§–∞–π–ª–∏:**
`/ua-sources/app/tasks/etl_workers.py`

–°—Ç–∞—Ç—É—Å: `/parsing` –∞–±–æ `/etl`"""
    
    # AI/ML
    if any(kw in text_lower for kw in ["ai", "ml", "llm", "council", "–º–æ–¥–µ–ª"]):
        return """üß† **AI/ML System**

**LLM Council** (5 –º–æ–¥–µ–ª–µ–π):
1. Groq (Llama 3 70B)
2. Google Gemini 1.5 Pro
3. Cohere Command R+
4. Together.ai (Llama 3)
5. Mistral Large

**–ü—Ä–æ—Ü–µ—Å:**
‚Ä¢ Stage 1: Opinions (–ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ)
‚Ä¢ Stage 2: Peer review
‚Ä¢ Stage 3: Synthesis

**–Ü–Ω—à—ñ AI:**
‚Ä¢ Embedding service (384-dim)
‚Ä¢ Semantic search
‚Ä¢ Reranking models

**–†–µ–∂–∏–º–∏:**
‚Ä¢ Fast (1 –º–æ–¥–µ–ª—å, ~500ms)
‚Ä¢ Council (5 –º–æ–¥–µ–ª–µ–π, ~10s)

–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–±–∏—Ä–∞—î—Ç—å—Å—è –ø–æ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ –ø–∏—Ç–∞–Ω–Ω—è!"""
    
    # Infrastructure
    if any(kw in text_lower for kw in ["deploy", "k8s", "kubernetes", "docker", "—ñ–Ω—Ñ—Ä–∞"]):
        return """üöÄ **Infrastructure**

**Local (Development):**
‚Ä¢ Docker Compose
‚Ä¢ 8 —Å–µ—Ä–≤—ñ—Å—ñ–≤
‚Ä¢ Hot reload

**Production:**
‚Ä¢ Kubernetes (K3s)
‚Ä¢ ArgoCD (GitOps)
‚Ä¢ Helm charts

**Monitoring:**
‚Ä¢ Grafana dashboards
‚Ä¢ Prometheus metrics
‚Ä¢ Health checks

**CI/CD:**
‚Ä¢ GitHub Actions
‚Ä¢ Auto-deploy on push
‚Ä¢ Multi-environment

**Ngrok:**
‚Ä¢ Tunneling –¥–ª—è dev
‚Ä¢ Auto SSH config update

–ö–æ–º–∞–Ω–¥–∏:
‚Ä¢ `/cluster` - K8s —Å—Ç–∞—Ç—É—Å
‚Ä¢ `/docker` - –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏"""
    
    # Telegram bot
    if any(kw in text_lower for kw in ["–±–æ—Ç", "telegram", "—Ç–µ–ª–µ–≥—Ä–∞–º"]):
        return """ü§ñ **Telegram Bot**

**–ú–æ–∂–ª–∏–≤–æ—Å—Ç—ñ:**
‚Ä¢ üìä –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ (OpenSearch, Qdrant, Celery)
‚Ä¢ üíª –ü—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è (Python, Bash)
‚Ä¢ üîó Auto ngrok/SSH update
‚Ä¢ üß† AI Council –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –ø–∏—Ç–∞–Ω—å
‚Ä¢ üìù –ü—Ä–∏—Ä–æ–¥–Ω–∞ –º–æ–≤–∞ (—É–∫—Ä–∞—ó–Ω—Å—å–∫–∞)

**–†–µ–∂–∏–º–∏:**
‚Ä¢ Fast - –ø—Ä–æ—Å—Ç—ñ –∑–∞–ø–∏—Ç–∏
‚Ä¢ Council - —Å–∫–ª–∞–¥–Ω—ñ –∞–Ω–∞–ª—ñ–∑–∏

**–ö–æ–º–∞–Ω–¥–∏:**
‚Ä¢ –°–∏—Å—Ç–µ–º–Ω—ñ: /status, /disk, /memory
‚Ä¢ Predator: /opensearch, /qdrant, /etl
‚Ä¢ AI: /code, /bash, /test
‚Ä¢ –ú–µ–Ω—é: /start, /help

**–§–∞–π–ª–∏:**
`/scripts/telegram_bot.py`

–Ø —ñ —î —Ü–µ–π –±–æ—Ç! üòä"""
    
    # –ü—Ä–æ–µ–∫—Ç–∏ / –∑–∞–≥–∞–ª—å–Ω–µ
    if any(kw in text_lower for kw in ["predator", "–ø—Ä–æ–µ–∫—Ç", "—â–æ —Ü–µ", "–æ–ø–∏—Å"]):
        return """üéØ **Predator Analytics**

**–©–æ —Ü–µ:**
–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏—Ö –±—ñ–∑–Ω–µ—Å-–¥–∞–Ω–∏—Ö –∑ AI.

**–û—Å–Ω–æ–≤–Ω—ñ —Ñ—ñ—á—ñ:**
‚Ä¢ –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫ –∫–æ–º–ø–∞–Ω—ñ–π
‚Ä¢ –ê–Ω–∞–ª—ñ–∑ —Ç–µ–Ω–¥–µ—Ä—ñ–≤ (Prozorro)
‚Ä¢ AI-–∞—Å–∏—Å—Ç–æ–≤–∞–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
‚Ä¢ Real-time –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥

**Tech Stack:**
‚Ä¢ Frontend: React + TypeScript
‚Ä¢ Backend: FastAPI (Python)
‚Ä¢ DB: PostgreSQL + OpenSearch + Qdrant
‚Ä¢ AI: LLM Council (5 –º–æ–¥–µ–ª–µ–π)
‚Ä¢ Infra: Docker + K8s

**–î–∂–µ—Ä–µ–ª–∞ –¥–∞–Ω–∏—Ö:**
‚Ä¢ –Ñ–î–†, Prozorro, –ù–ë–£, YouControl

**GitHub:**
github.com/dima1203oleg/predator-analytics

–î–µ—Ç–∞–ª—å–Ω–æ: `/predator` –∞–±–æ –ø–∏—Ç–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ!"""
    
    return None  # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ knowledge base


# ============================================================
# MESSAGE PROCESSING
# ============================================================

async def process_message(text: str, chat_id: int, user_id: int) -> str:
    """Process incoming message"""
    text_lower = text.lower().strip()
    
    # Check for ngrok update
    if "ngrok" in text_lower and ("ssh:" in text_lower or "http:" in text_lower):
        ngrok_info = parse_ngrok_message(text)
        if ngrok_info:
            success, message = update_ssh_config(ngrok_info)
            return message
        return "‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ ngrok –¥–∞–Ω—ñ"
    
    # Check for commands
    if text.startswith("/"):
        parts = text[1:].split(maxsplit=1)
        cmd = parts[0].lower()
        args = parts[1] if len(parts) > 1 else ""
        
        handler = COMMANDS.get(cmd)
        if handler:
            return await handler(args)
        return "‚ùå –ù–µ–≤—ñ–¥–æ–º–∞ –∫–æ–º–∞–Ω–¥–∞. /help"
    
    # Check for emoji/text commands
    for key, cmd in EMOJI_MAP.items():
        if text_lower.startswith(key) or key in text_lower:
            handler = COMMANDS.get(cmd)
            if handler:
                return await handler("")
    
    # üÜï –ü–†–ò–†–û–î–ù–ê –ú–û–í–ê - AI –æ–±—Ä–æ–±–∫–∞
    return await process_natural_language(text, chat_id)


# ============================================================
# TELEGRAM API
# ============================================================

async def send_message(chat_id: int, text: str, reply_markup: Optional[Dict] = None) -> bool:
    """Send message to chat"""
    try:
        async with httpx.AsyncClient() as client:
            data = {
                "chat_id": chat_id,
                "text": text,
                "parse_mode": "Markdown"
            }
            if reply_markup:
                data["reply_markup"] = json.dumps(reply_markup)
            
            response = await client.post(f"{API_URL}/sendMessage", json=data)
            return response.status_code == 200
    except Exception as e:
        logger.error(f"Failed to send message: {e}")
        return False


async def delete_webhook() -> bool:
    """Delete webhook for polling mode"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(f"{API_URL}/deleteWebhook")
            return response.json().get("ok", False)
    except Exception as e:
        logger.error(f"Failed to delete webhook: {e}")
        return False


async def get_updates(offset: int = 0, timeout: int = 30) -> List[Dict]:
    """Get updates from Telegram"""
    try:
        async with httpx.AsyncClient(timeout=timeout + 10) as client:
            response = await client.get(
                f"{API_URL}/getUpdates",
                params={"offset": offset, "timeout": timeout}
            )
            result = response.json()
            return result.get("result", [])
    except Exception as e:
        logger.error(f"Failed to get updates: {e}")
        return []



# ============================================================
# MAIN LOOP
# ============================================================

async def run_bot():
    """Main bot loop"""
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë        ü§ñ Predator Analytics Telegram Bot                    ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –ø–∞—Ä—Å–∏–Ω–≥ ngrok URLs                          ‚ïë
‚ïë  ‚úÖ –û–Ω–æ–≤–ª–µ–Ω–Ω—è SSH config                                     ‚ïë
‚ïë  ‚úÖ –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Å–µ—Ä–≤–µ—Ä–∞                                       ‚ïë
‚ïë  ‚úÖ Docker/K8s —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è                                    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    logger.info(f"üöÄ Starting bot with token: {BOT_TOKEN[:15]}...")
    
    # Delete existing webhook
    await delete_webhook()
    logger.info("‚úÖ Webhook deleted, starting polling...")
    
    offset = 0
    
    while True:
        try:
            updates = await get_updates(offset=offset, timeout=30)
            
            for update in updates:
                offset = update["update_id"] + 1
                
                if "message" not in update:
                    continue
                
                message = update["message"]
                chat_id = message["chat"]["id"]
                user_id = message["from"]["id"]
                text = message.get("text", "")
                
                if not text:
                    continue
                
                username = message["from"].get("username", "Unknown")
                logger.info(f"üì© [{username}] {text[:50]}...")
                
                # Process message
                response = await process_message(text, chat_id, user_id)
                
                # Send reply with menu for /start
                show_menu = text.lower() in ["/start", "/menu"]
                await send_message(
                    chat_id=chat_id,
                    text=response,
                    reply_markup=MAIN_MENU if show_menu else None
                )
                logger.info(f"‚úÖ Replied to {username}")
                
        except asyncio.CancelledError:
            logger.info("üõë Bot stopped")
            break
        except Exception as e:
            logger.error(f"‚ùå Error: {e}")
            await asyncio.sleep(5)


if __name__ == "__main__":
    try:
        asyncio.run(run_bot())
    except KeyboardInterrupt:
        print("\nüëã Bot stopped by user")
