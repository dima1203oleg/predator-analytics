
# üìã –¢–µ—Ö–Ω—ñ—á–Ω–µ –ó–∞–≤–¥–∞–Ω–Ω—è: LoRA Trainer Job v1.0

–í–µ—Ä—Å—ñ—è: 1.1 (Extended Ecosystem Support)  
–°—Ç–∞—Ç—É—Å: Ready for Implementation

---

## 1. –ú–µ—Ç–∞

–†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ **–æ–∫—Ä–µ–º–∏–π Job/CronJob**, —è–∫–∏–π:

1. –ß–∏—Ç–∞—î –Ω–∞–≤—á–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ –∑ JSONL-—Ñ–∞–π–ª—ñ–≤, –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏—Ö Self-Learning Loop (`training_export.py`).
2. –ó–∞–ø—É—Å–∫–∞—î LoRA-—Ñ–∞–π–Ω—Ç—é–Ω—ñ–Ω–≥ –±–∞–∑–æ–≤–æ—ó LLM-–º–æ–¥–µ–ª—ñ.
   - –ü—ñ–¥—Ç—Ä–∏–º—É—î **–ª–æ–∫–∞–ª—å–Ω–µ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è** (HuggingFace/PEFT).
   - –ü—ñ–¥—Ç—Ä–∏–º—É—î **–¥–µ–ª–µ–≥—É–≤–∞–Ω–Ω—è –≤ H2O LLM Studio** (—á–µ—Ä–µ–∑ API).
3. –ó–±–µ—Ä—ñ–≥–∞—î –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∏ (LoRA-–∞–¥–∞–ø—Ç–µ—Ä) —Ç–∞ –º–µ—Ç—Ä–∏–∫–∏.
4. –õ–æ–≥—É—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∑–∞–ø—É—Å–∫ —É —Ç–∞–±–ª–∏—Ü—é `lora_training_runs`.
5. –ï–∫—Å–ø–æ—Ä—Ç—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è inference-–±–µ–∫–µ–Ω–¥—ñ–≤: **Ollama** —Ç–∞ **LM Studio**.

---

## 2. –ö–æ–Ω—Ç–µ–∫—Å—Ç —ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ

### 2.1. –Ü–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ v20.0
- **–ë–î:** `brain_training_samples`.
- **–ï–∫—Å–ø–æ—Ä—Ç:** JSONL —É `/data/datasets/brain`.

### 2.2. –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ–π–Ω—ñ —Ç–æ—á–∫–∏ (v21.0 Extended)
- **Local Native:** HuggingFace `peft` + `transformers` (default).
- **External Training:** **H2O LLM Studio** (—á–µ—Ä–µ–∑ REST API/Webhook).
- **Inference Targets:**
  - **Ollama:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è `Modelfile`.
  - **LM Studio:** –ï–∫—Å–ø–æ—Ä—Ç –∞–¥–∞–ø—Ç–µ—Ä—ñ–≤ —É GGUF-—Å—É–º—ñ—Å–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ –∞–±–æ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è.

---

## 3. –§—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ –≤–∏–º–æ–≥–∏

### 3.1. –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è (ENV)

–î–æ–¥–∞—é—Ç—å—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –≤–∏–±–æ—Ä—É –±–µ–∫–µ–Ω–¥—É —Ç–∞ —Ü—ñ–ª–µ–π –µ–∫—Å–ø–æ—Ä—Ç—É:

```bash
# Backend Selection
TRAINING_BACKEND="hf-peft" # –∞–±–æ "h2o"

# Native Settings (HF/PEFT)
BASE_MODEL_NAME="llama3-8b"
LORA_RANK="8"
TRAIN_EPOCHS="3"

# H2O Settings (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è, —è–∫—â–æ TRAINING_BACKEND="h2o")
H2O_API_URL="https://h2o-llm.internal"
H2O_API_KEY="secret-key-from-vault"

# Artifact Export
EXPORT_TARGETS="ollama,lmstudio" # —Å–ø–∏—Å–æ–∫ —Ü—ñ–ª–µ–π —á–µ—Ä–µ–∑ –∫–æ–º—É
```

### 3.2. –õ–æ–≥—ñ–∫–∞ —Ä–æ–±–æ—Ç–∏ (Pipeline)

1. **Discovery & Prep:**
   - –ü–æ—à—É–∫ `brain_dataset_*.jsonl` —É `/data/datasets/brain`.
   - –í–∞–ª—ñ–¥–∞—Ü—ñ—è JSONL —Ç–∞ –º–µ—Ä–¥–∂ —É —î–¥–∏–Ω–∏–π —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª.

2. **Training Execution:**
   - **Scenario A (Native `hf-peft`):**
     - –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –±–∞–∑–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ.
     - –ó–∞–ø—É—Å–∫ `SFTTrainer` (HuggingFace).
     - –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∞–¥–∞–ø—Ç–µ—Ä–∞ –ª–æ–∫–∞–ª—å–Ω–æ –≤ `/data/adapters/brain/{run_id}/`.
   - **Scenario B (H2O LLM Studio):**
     - –í—ñ–¥–ø—Ä–∞–≤–∫–∞ JSONL-–¥–∞—Ç–∞—Å–µ—Ç—É –Ω–∞ H2O API (`POST /api/datasets`).
     - –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É (`POST /api/experiments`) –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é LoRA.
     - –ü–æ–ª–ª—ñ–Ω–≥ —Å—Ç–∞—Ç—É—Å—É (`GET /api/experiments/{id}`).
     - –ü—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è: –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –±—ñ–Ω–∞—Ä–Ω–∏–∫—ñ–≤ –∞–¥–∞–ø—Ç–µ—Ä–∞ (`GET /api/experiments/{id}/download`).

3. **Post-Processing (Export):**
   - **LM Studio:**
     - –ü–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—è, —â–æ –∞–¥–∞–ø—Ç–µ—Ä –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É —Ñ–æ—Ä–º–∞—Ç—ñ, —è–∫–∏–π LM Studio –º–æ–∂–µ –ø—ñ–¥—Ç—è–≥–Ω—É—Ç–∏ (–∞–±–æ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —É GGUF —á–µ—Ä–µ–∑ `llama.cpp` —Å–∫—Ä–∏–ø—Ç, —è–∫—â–æ —Ä–µ—Å—É—Ä—Å–∏ –¥–æ–∑–≤–æ–ª—è—é—Ç—å).
     - –°—Ç–≤–æ—Ä–∏—Ç–∏ –º–µ—Ç–∞-—Ñ–∞–π–ª `lmstudio_config.json`.
   - **Ollama:**
     - –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ñ–∞–π–ª `Modelfile`, —è–∫–∏–π –±–∞–∑—É—î—Ç—å—Å—è –Ω–∞ `FROM {BASE_MODEL}` —Ç–∞ `ADAPTER {path_to_adapter}`.
     - (–û–ø—Ü—ñ–π–Ω–æ) –í–∏–∫–æ–Ω–∞—Ç–∏ –∫–æ–º–∞–Ω–¥—É `ollama create predator-v21:{run_id} -f Modelfile` —á–µ—Ä–µ–∑ API Ollama.

4. **Logging:**
   - –ó–∞–ø–∏—Å —É `lora_training_runs` —ñ–∑ –∑–∞–∑–Ω–∞—á–µ–Ω–Ω—è–º `backend` ('hf-peft'/'h2o') —Ç–∞ `external_run_id` (–¥–ª—è H2O).

---

## 4. –°—Ö–µ–º–∞ –ë–î: lora_training_runs (Extended)

```sql
CREATE TABLE IF NOT EXISTS lora_training_runs (
    id              BIGSERIAL PRIMARY KEY,
    dataset_paths   TEXT[] NOT NULL,
    base_model      TEXT NOT NULL,
    adapter_path    TEXT,
    
    -- Execution Context
    backend         TEXT NOT NULL DEFAULT 'hf-peft', -- 'hf-peft' | 'h2o'
    external_run_id TEXT,                            -- ID –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É –≤ H2O
    
    metrics         JSONB NOT NULL DEFAULT '{}'::jsonb, -- loss, accuracy, etc.
    status          TEXT NOT NULL,                      -- 'RUNNING', 'COMPLETED', 'FAILED'
    error_message   TEXT,
    
    started_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    finished_at     TIMESTAMPTZ,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
```

---

## 5. –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥—É–ª—è `app/lora_trainer/`

- `trainer_native.py` ‚Äî –ª–æ–≥—ñ–∫–∞ `peft`/`transformers`.
- `trainer_h2o.py` ‚Äî –∫–ª—ñ—î–Ω—Ç –¥–ª—è H2O LLM Studio API.
- `exporters.py` ‚Äî –ª–æ–≥—ñ–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó `Modelfile` —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–ª—è LM Studio.
- `run_trainer.py` ‚Äî Entrypoint, —á–∏—Ç–∞—î ENV —Ç–∞ –≤–∏–±–∏—Ä–∞—î —Å—Ç—Ä–∞—Ç–µ–≥—ñ—é.

---

## 6. Helm & Resources

- –î–ª—è `hf-peft` —Ä–µ–∂–∏–º—É –∫—Ä–∏—Ç–∏—á–Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å GPU (NVIDIA node selector).
- –î–ª—è `h2o` —Ä–µ–∂–∏–º—É Job –ø—Ä–∞—Ü—é—î —è–∫ –ª–µ–≥–∫–æ–≤–∞–≥–æ–≤–∏–π –∫–ª—ñ—î–Ω—Ç (–º–æ–∂–Ω–∞ –∑–∞–ø—É—Å–∫–∞—Ç–∏ –Ω–∞ CPU, –ø–æ—Ç—Ä—ñ–±–µ–Ω –ª–∏—à–µ –¥–æ—Å—Ç—É–ø –¥–æ –º–µ—Ä–µ–∂—ñ).

---

## 7. Definition of Done

1. Job —É—Å–ø—ñ—à–Ω–æ —Ç—Ä–µ–Ω—É—î –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ ("hf-peft").
2. Job —É—Å–ø—ñ—à–Ω–æ –¥–µ–ª–µ–≥—É—î —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –≤ H2O (—è–∫—â–æ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ `TRAINING_BACKEND="h2o"`).
3. –ê—Ä—Ç–µ—Ñ–∞–∫—Ç–∏ (–∞–¥–∞–ø—Ç–µ—Ä) –∫–æ—Ä–µ–∫—Ç–Ω–æ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –Ω–∞ PVC.
4. –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≥–µ–Ω–µ—Ä—É—î—Ç—å—Å—è `Modelfile` –¥–ª—è Ollama.
5. –ê–¥–º—ñ–Ω –±–∞—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å "Remote Training (H2O)" —É –¥–∞—à–±–æ—Ä–¥—ñ.
