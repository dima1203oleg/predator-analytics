# values.yaml
# Helm-values для середовища NVIDIA Server (lab-gpu)
# GPU-лабораторія для NAS/AutoML, важких моделей, staging

namespace: predator-nvidia

global:
  env: "lab-gpu"
  imageRegistry: ghcr.io/dima1203oleg
  # Trigger deployment: 2025-12-02

# ============ Backend ============
backend:
  enabled: true
  image:
    repository: ghcr.io/dima1203oleg/predator-backend
    tag: "v22.0.x"
    pullPolicy: Always
  replicas: 1
  resources:
    limits:
      cpu: "2"
      memory: "4Gi"
    requests:
      cpu: "1"
      memory: "2Gi"
  gpu:
    enabled: false # Backend API doesn't need GPU directly, uses Ollama via API
    resourceName: "nvidia.com/gpu"
    count: 0
  service:
    type: ClusterIP
    port: 8000
  env:
    - name: ENV
      value: "lab-gpu"
    - name: DEBUG
      value: "false"
    - name: CUDA_VISIBLE_DEVICES
      value: "0"

# ============ Frontend ============
frontend:
  enabled: true
  image:
    repository: ghcr.io/dima1203oleg/predator-frontend
    tag: "v22.0.x"
    pullPolicy: Always
  replicas: 1
  resources:
    limits:
      cpu: "0.5"
      memory: "512Mi"
    requests:
      cpu: "0.25"
      memory: "256Mi"
  service:
    type: ClusterIP
    port: 80

# ============ NAS / AutoML ============
nas:
  enabled: false # Disabled until backend images are ready
  datasets:
    - "/data/real-sales.csv"
    - "/data/customs-ua-8y.parquet"
  automl: true # Повний AutoML з GPU
  resources:
    limits:
      cpu: "4"
      memory: "8Gi"
      nvidia.com/gpu: 1
    requests:
      cpu: "2"
      memory: "4Gi"

# ============ PostgreSQL ============
postgresql:
  enabled: true
  auth:
    postgresPassword: "nvidia-prod-password"
    database: "predator"
  primary:
    persistence:
      enabled: true
      size: 10Gi
    resources:
      limits:
        cpu: "1"
        memory: "1Gi"

# ============ Redis ============
redis:
  enabled: true
  auth:
    enabled: true
    password: "redis-nvidia-secret"
  master:
    persistence:
      enabled: true
      size: 1Gi
    resources:
      limits:
        cpu: "0.5"
        memory: "512Mi"

# ============ MinIO (S3 Storage) ============
minio:
  enabled: true
  auth:
    rootUser: "minio-admin"
    rootPassword: "minio-nvidia-secret"
  persistence:
    enabled: true
    size: 20Gi
  resources:
    limits:
      cpu: "1"
      memory: "1Gi"
  service:
    type: ClusterIP
    ports:
      api: 9000
      console: 9001

# ============ OpenSearch ============
opensearch:
  enabled: true
  replicas: 1
  persistence:
    enabled: true
    size: 10Gi
  resources:
    limits:
      cpu: "2"
      memory: "4Gi"
    requests:
      cpu: "1"
      memory: "2Gi"
  service:
    type: ClusterIP
    port: 9200

# ============ MLOps Pipeline ============
mlOps:
  enabled: true
  selfImprovement: true
  flower:
    enabled: true
    user: "admin"
    # password set via env var FLOWER_PASSWORD
  mlflow:
    enabled: true
    persistence:
      size: 5Gi

# ============ Qdrant (Vector DB) ============
qdrant:
  enabled: true
  replicas: 1
  persistence:
    enabled: true
    size: 5Gi
  resources:
    limits:
      cpu: "1"
      memory: "2Gi"
    requests:
      cpu: "0.5"
      memory: "1Gi"
  service:
    type: ClusterIP
    port: 6333

# ============ Ollama (LLM Runtime) ============
ollama:
  enabled: true
  image:
    repository: ollama/ollama
    tag: "latest"
  resources:
    limits:
      cpu: "4"
      memory: "16Gi"
      nvidia.com/gpu: 1
    requests:
      cpu: "2"
      memory: "8Gi"
  persistence:
    enabled: true
    size: 50Gi
  models:
    - "llama3.2"
    - "qwen2.5"
    - "qwen3"
    - "nomic-embed-text"
  service:
    type: ClusterIP
    port: 11434

# ============ Monitoring ============
monitoring:
  enabled: true
  prometheus:
    enabled: true
    persistence:
      size: 5Gi
  grafana:
    enabled: true
    adminPassword: "grafana-nvidia-admin"
    persistence:
      size: 1Gi
  loki:
    enabled: true
    persistence:
      size: 5Gi

# ============ Node Selector ============
nodeSelector:
  gpu: "true"

# ============ Tolerations ============
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"

# ============ Affinity ============
affinity: {}
